name: Feed

on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  rag:
    runs-on: ubuntu-latest
    outputs:
      changed: ${{ steps.commit.outputs.changed }}
      sha: ${{ steps.commit.outputs.sha }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Sanity check (repo chroma_db exists)
        run: |
          echo "chroma_db file count:"
          find chroma_db -type f | wc -l
          n=$(find chroma_db -type f | wc -l)
          if [ "$n" -lt 5 ]; then
            echo "ERROR: chroma_db seems empty. Run the Ingest workflow to rebuild/commit it."
            exit 1
          fi

      - name: Start stack (db + ollama + backend)
        env:
          RAG_AUTO_INDEX: "false"
          RAG_REBUILD_ON_START: "false"
          RAG_REINDEX_ENABLED: "true"
        run: |
          docker compose -f docker-compose.yml up -d --build

      - name: Wait for backend
        env:
          REACT_NATIVE_PACKAGER_HOSTNAME: 127.0.0.1
        run: |
          ok=0
          for i in {1..600}; do
            if curl -fsS http://localhost:8000/health >/dev/null; then
              ok=$((ok+1))
              [ "$ok" -ge 3 ] && break
            else
              ok=0
            fi
            sleep 2
          done

          if [ "$ok" -ge 3 ]; then
            echo "backend is stable"
          else
            echo "Backend did not become ready in time"
            docker compose logs --no-color backend || true
            exit 1
          fi

      - name: Fix permissions for feed dirs
        run: |
          sudo chown -R "$USER:$USER" frontend/app/public || true
          chmod -R u+rwX frontend/app/public || true

      - name: Generate weather tweet post
        env:
          LAT: "35.2810"
          LON: "139.6722"
          TZ_NAME: "Asia/Tokyo"
          RAG_TOP_K: 16
          CURL_MAX_TIME: 64
          PLACE: "Yokosuka"
          FEED_PATH: frontend/app/public
          LATEST_PATH: frontend/app/public/latest.json
          MAX_WORDS: 128
          REACT_NATIVE_PACKAGER_HOSTNAME: 127.0.0.1
        run: |
          python scripts/generate_talk.py

      - name: Stop stack
        env:
          REACT_NATIVE_PACKAGER_HOSTNAME: 127.0.0.1
        if: always()
        run: |
          docker compose down

      - name: Commit & push if changed
        id: commit
        run: |
          if git diff --quiet; then
            echo "No changes"
            echo "changed=0" >> "$GITHUB_OUTPUT"
            echo "sha=" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git pull --ff-only origin main

          git add frontend/app/public/feed/*.json || true
          git add frontend/app/public/latest.json || true
          git add frontend/app/public/snapshot/*.json || true

          if git diff --cached --quiet; then
            echo "No staged changes"
            echo "changed=0" >> "$GITHUB_OUTPUT"
            echo "sha=" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          git commit -m "chore: image feed"
          git push origin HEAD:main

          echo "changed=1" >> "$GITHUB_OUTPUT"
          echo "sha=$(git rev-parse HEAD)" >> "$GITHUB_OUTPUT"

  illustrate:
    needs: rag
    if: needs.rag.outputs.changed == '1'
    runs-on: ubuntu-latest
    outputs:
      changed: ${{ steps.commit.outputs.changed }}
      sha: ${{ steps.commit.outputs.sha }}
    steps:
      - name: Checkout (main)
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0

      - name: Sync to latest main (ff-only)
        run: |
          set -euo pipefail
          git pull --ff-only origin main

      - name: Verify rag commit is included
        env:
          RAG_SHA: ${{ needs.rag.outputs.sha }}
        run: |
          set -euo pipefail
          if [ -n "${RAG_SHA}" ]; then
            git merge-base --is-ancestor "${RAG_SHA}" HEAD || {
              echo "HEAD does not include rag sha yet; fetching and resetting."
              git fetch origin "${RAG_SHA}"
              git reset --hard "${RAG_SHA}"
            }
          fi

      - name: Free disk space
        run: |
          set -euo pipefail
          df -h
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc 2>/dev/null || true
          sudo docker system prune -af --volumes 2>/dev/null || true
          df -h

      - name: Setup Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Cache Hugging Face + Torch
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/huggingface
            ~/.cache/torch
          key: ${{ runner.os }}-hf-torch-sdturbo-v1
          restore-keys: |
            ${{ runner.os }}-hf-torch-sdturbo-
            ${{ runner.os }}-hf-torch-

      - name: Install SD deps (CPU)
        run: |
          python -m pip install --upgrade pip
          python -m pip install --index-url https://download.pytorch.org/whl/cpu torch
          python -m pip install diffusers transformers accelerate safetensors pillow

      - name: Generate illustrated image (sd-turbo) and patch feed
        env:
          LATEST_PATH: frontend/app/public/latest.json
          FEED_DIR: frontend/app/public/feed
          OUT_DIR: frontend/app/public/image
          MODEL_ID: stabilityai/sd-turbo
          STEPS: "2"
          BASE_SIZE: "512"
          PAGE_W: "640" # VGA
          PAGE_H: "480" # VGA
          BRAND: "GOODDAY YOKOSUKA"
          PLACE: "Yokosuka"
        run: |
          set -euo pipefail
          test -f "$LATEST_PATH"

          python - <<'PY'
          import os, re, json, hashlib
          from pathlib import Path
          from datetime import datetime, timezone

          import torch
          from diffusers import DiffusionPipeline
          from PIL import Image, ImageDraw, ImageFont

          LATEST_PATH = Path(os.environ["LATEST_PATH"])
          FEED_DIR = Path(os.environ.get("FEED_DIR", "frontend/app/public/feed"))
          OUT_DIR = Path(os.environ.get("OUT_DIR", "frontend/app/public/image"))
          MODEL_ID = os.environ.get("MODEL_ID", "stabilityai/sd-turbo")
          STEPS = int(os.environ.get("STEPS", "2"))
          BASE_SIZE = int(os.environ.get("BASE_SIZE"))
          PAGE_W = int(os.environ.get("PAGE_W"))
          PAGE_H = int(os.environ.get("PAGE_H"))
          BRAND = os.environ.get("BRAND", "GOODDAY YOKOSUKA")
          PLACE = os.environ.get("PLACE", "")

          def load_json(p: Path):
            return json.loads(p.read_text(encoding="utf-8"))

          def dump_json(p: Path, obj):
            p.write_text(json.dumps(obj, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")

          def pick_font(size: int, bold: bool = False):
            candidates = []
            if bold:
              candidates += [
                "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",
                "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
              ]
            else:
              candidates += [
                "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
                "/usr/share/fonts/truetype/dejavu/DejaVuSansCondensed.ttf",
              ]
            for p in candidates:
              try:
                return ImageFont.truetype(p, size=size)
              except Exception:
                pass
            return ImageFont.load_default()

          def clean_for_prompt(text: str) -> str:
            t = re.sub(r"https?://\S+", "", text)
            t = re.sub(r"#\w+", "", t)
            t = re.sub(r"\s+", " ", t).strip()
            return t[:220]

          def slug(s: str) -> str:
            s = re.sub(r"\s+", "_", s.strip())
            s = re.sub(r"[^0-9A-Za-z_\-]", "", s)
            return s[:60] or "item"

          latest = load_json(LATEST_PATH)
          if not isinstance(latest, dict) or not latest.get("date") or not latest.get("text"):
            print("latest.json not in expected single-object shape (date/text). Skip.")
            raise SystemExit(0)

          date = str(latest.get("date", "")).strip()
          text = str(latest.get("text", "")).strip()
          place = str(latest.get("place", "") or PLACE).strip()
          generated_at = str(latest.get("generated_at", "")).strip()

          # Deterministic 8-hex seed derived from the feed content.
          # Used for the Stable Diffusion seed and as a fallback stem when no feed file is found.
          seed_src = f"{date}\n{place}\n{generated_at}\n{text}".encode("utf-8")
          seed_hex8 = hashlib.sha1(seed_src).hexdigest()[:8]

          feeds = []
          if FEED_DIR.exists():
              feeds = sorted(FEED_DIR.glob("feed_*.json"), key=lambda x: x.name, reverse=True)

          feed_stem = feeds[0].stem if feeds else f"{slug(date)}_{seed_hex8}"
          fn = f"{feed_stem}.png"
          OUT_DIR.mkdir(parents=True, exist_ok=True)
          out_path = OUT_DIR / fn
          rel_url = "/" + str(out_path.relative_to(Path("frontend/app/public"))).replace("\\", "/")

          if latest.get("image_url") == rel_url and out_path.exists():
            print("Already generated; skip.")
            raise SystemExit(0)

          core = clean_for_prompt(text)
          prompt = (
            "Japanese picture illustration, illustrated image style, "
            "watercolor and colored pencil, soft warm light, cute and simple, "
            "hand-drawn, minimal details, friendly atmosphere, "
            f"scene in {place}. Inspired by this message: {core}"
          )
          negative = (
            "nsfw, nude, sexual, gore, violence, hate, disturbing, "
            "text, watermark, logo, letters, words, typography, caption, subtitles, signature, "
            "low quality, blurry"
          )

          device = "cuda" if torch.cuda.is_available() else "cpu"
          dtype = torch.float16 if device == "cuda" else torch.float32
          pipe = DiffusionPipeline.from_pretrained(MODEL_ID, torch_dtype=dtype).to(device)

          try:
            pipe.set_progress_bar_config(disable=True)
          except Exception:
            pass
          try:
            pipe.enable_attention_slicing()
          except Exception:
            pass
          try:
            pipe.enable_vae_slicing()
          except Exception:
            pass

          guidance_scale = 0.0
          seed = int(seed_hex8, 16)
          g = torch.Generator(device=device).manual_seed(seed)

          img = pipe(
            prompt=prompt,
            negative_prompt=negative,
            guidance_scale=guidance_scale,
            num_inference_steps=max(1, min(4, STEPS)),
            width=PAGE_W,
            height=PAGE_H,
            generator=g,
          ).images[0].convert("RGB")

          page = img.convert("RGB")
          page.save(out_path, format="PNG", optimize=True)

          latest["image_url"] = rel_url
          latest["image_prompt"] = prompt
          latest["image_model"] = MODEL_ID
          latest["image_generated_at"] = now_iso
          dump_json(LATEST_PATH, latest)

          def patch_feed_file(p: Path) -> bool:
            try:
              obj = load_json(p)
            except Exception:
              return False
            if not isinstance(obj, dict) or not isinstance(obj.get("items"), list):
              return False
            changed = False
            for it in obj["items"]:
              if not isinstance(it, dict):
                continue
              same_id = bool(generated_at) and str(it.get("id", "")) == generated_at
              same_dt = str(it.get("date", "")) == date and str(it.get("text", "")) == text
              if same_id or same_dt:
                  it["id"] = feed_stem
                  it["image"] = rel_url
                  it["image_url"] = rel_url
                  it["image_prompt"] = prompt
                  it["image_model"] = MODEL_ID
                  it["image_generated_at"] = now_iso
                  changed = True
            if changed:
              dump_json(p, obj)
            return changed

          if FEED_DIR.exists():
            feeds = sorted(FEED_DIR.glob("feed_*.json"), key=lambda x: x.name, reverse=True)
            if feeds:
              patch_feed_file(feeds[0])

          print("Generated:", out_path, "url:", rel_url)
          PY

      - name: Commit & push illustrated changes if any
        id: commit
        run: |
          if git diff --quiet; then
            echo "No changes"
            echo "changed=0" >> "$GITHUB_OUTPUT"
            echo "sha=" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git pull --ff-only origin main

          git add frontend/app/public/latest.json || true
          git add frontend/app/public/feed/*.json || true
          git add frontend/app/public/image/*.png || true

          if git diff --cached --quiet; then
            echo "No staged changes"
            echo "changed=0" >> "$GITHUB_OUTPUT"
            echo "sha=" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          git commit -m "chore: illustrated image"
          git push origin HEAD:main

          echo "changed=1" >> "$GITHUB_OUTPUT"
          echo "sha=$(git rev-parse HEAD)" >> "$GITHUB_OUTPUT"

  pages:
    needs: [rag, illustrate]
    if: needs.rag.outputs.changed == '1'
    uses: ./.github/workflows/pages.yml
    with:
      ref: main
    permissions:
      contents: read
      pages: write
      id-token: write